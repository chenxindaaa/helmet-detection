Plotting labels...
[34m[1mautoanchor: [39m[22mAnalyzing anchors... anchors/target = 5.38, Best Possible Recall (BPR) = 1.0000
                 from  n    params  module                                  arguments
  0                -1  1      8800  models.common.Focus                     [3, 80, 3]
  1                -1  1    115520  models.common.Conv                      [80, 160, 3, 2]
  2                -1  4    309120  models.common.C3                        [160, 160, 4]
  3                -1  1    461440  models.common.Conv                      [160, 320, 3, 2]
  4                -1 12   3285760  models.common.C3                        [320, 320, 12]
  5                -1  1   1844480  models.common.Conv                      [320, 640, 3, 2]
  6                -1 12  13125120  models.common.C3                        [640, 640, 12]
  7                -1  1   7375360  models.common.Conv                      [640, 1280, 3, 2]
  8                -1  1   4099840  models.common.SPP                       [1280, 1280, [5, 9, 13]]
  9                -1  4  19676160  models.common.C3                        [1280, 1280, 4, False]
 10                -1  1    820480  models.common.Conv                      [1280, 640, 1, 1]
 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']
 12           [-1, 6]  1         0  models.common.Concat                    [1]
 13                -1  4   5332480  models.common.C3                        [1280, 640, 4, False]
 14                -1  1    205440  models.common.Conv                      [640, 320, 1, 1]
 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']
 16           [-1, 4]  1         0  models.common.Concat                    [1]
 17                -1  4   1335040  models.common.C3                        [640, 320, 4, False]
 18                -1  1    922240  models.common.Conv                      [320, 320, 3, 2]
 19          [-1, 14]  1         0  models.common.Concat                    [1]
 20                -1  4   4922880  models.common.C3                        [640, 640, 4, False]
 21                -1  1   3687680  models.common.Conv                      [640, 640, 3, 2]
 22          [-1, 10]  1         0  models.common.Concat                    [1]
 23                -1  4  19676160  models.common.C3                        [1280, 1280, 4, False]
 24      [17, 20, 23]  1     47103  models.yolo.Detect                      [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [320, 640, 1280]]
Model Summary: 607 layers, 87251103 parameters, 87251103 gradients, 217.3 GFLOPs
Scaled weight_decay = 0.0005
[34m[1moptimizer:[39m[22m SGD with parameter groups 131 weight, 134 weight (no decay), 134 bias
[34m[1mtrain: [39m[22mScanning 'data\helmet\labels\train' images and labels...600 found, 0 missing, 10 empty, 0 corrupted: 100%|â–ˆ| 600
[34m[1mtrain: [39m[22mWARNING: corrupt JPEG restored and saved data\helmet\images\train\000002.jpg
[34m[1mtrain: [39m[22mWARNING: corrupt JPEG restored and saved data\helmet\images\train\000003.jpg
[34m[1mtrain: [39m[22mWARNING: corrupt JPEG restored and saved data\helmet\images\train\000006.jpg
[34m[1mtrain: [39m[22mWARNING: corrupt JPEG restored and saved data\helmet\images\train\000007.jpg
[34m[1mtrain: [39m[22mWARNING: corrupt JPEG restored and saved data\helmet\images\train\000011.jpg
[34m[1mtrain: [39m[22mWARNING: corrupt JPEG restored and saved data\helmet\images\train\000056.jpg
[34m[1mtrain: [39m[22mWARNING: corrupt JPEG restored and saved data\helmet\images\train\000063.jpg
[34m[1mtrain: [39m[22mWARNING: corrupt JPEG restored and saved data\helmet\images\train\000086.jpg
[34m[1mtrain: [39m[22mWARNING: corrupt JPEG restored and saved data\helmet\images\train\000101.jpg
[34m[1mtrain: [39m[22mWARNING: corrupt JPEG restored and saved data\helmet\images\train\000108.jpg
[34m[1mtrain: [39m[22mWARNING: corrupt JPEG restored and saved data\helmet\images\train\000144.jpg
[34m[1mtrain: [39m[22mWARNING: corrupt JPEG restored and saved data\helmet\images\train\000149.jpg
[34m[1mtrain: [39m[22mWARNING: corrupt JPEG restored and saved data\helmet\images\train\000158.jpg
[34m[1mtrain: [39m[22mWARNING: corrupt JPEG restored and saved data\helmet\images\train\000162.jpg
[34m[1mtrain: [39m[22mWARNING: corrupt JPEG restored and saved data\helmet\images\train\000166.jpg
[34m[1mtrain: [39m[22mWARNING: corrupt JPEG restored and saved data\helmet\images\train\000173.jpg
[34m[1mtrain: [39m[22mWARNING: corrupt JPEG restored and saved data\helmet\images\train\000209.jpg
[34m[1mtrain: [39m[22mWARNING: corrupt JPEG restored and saved data\helmet\images\train\000250.jpg
[34m[1mtrain: [39m[22mWARNING: corrupt JPEG restored and saved data\helmet\images\train\000251.jpg
[34m[1mtrain: [39m[22mWARNING: corrupt JPEG restored and saved data\helmet\images\train\000256.jpg
[34m[1mtrain: [39m[22mWARNING: corrupt JPEG restored and saved data\helmet\images\train\000266.jpg
[34m[1mtrain: [39m[22mWARNING: corrupt JPEG restored and saved data\helmet\images\train\000272.jpg
[34m[1mtrain: [39m[22mWARNING: corrupt JPEG restored and saved data\helmet\images\train\000273.jpg
[34m[1mtrain: [39m[22mWARNING: corrupt JPEG restored and saved data\helmet\images\train\000301.jpg
[34m[1mtrain: [39m[22mWARNING: corrupt JPEG restored and saved data\helmet\images\train\000373.jpg
[34m[1mtrain: [39m[22mWARNING: corrupt JPEG restored and saved data\helmet\images\train\000376.jpg
[34m[1mtrain: [39m[22mWARNING: corrupt JPEG restored and saved data\helmet\images\train\000408.jpg
[34m[1mtrain: [39m[22mWARNING: corrupt JPEG restored and saved data\helmet\images\train\000431.jpg
[34m[1mtrain: [39m[22mWARNING: corrupt JPEG restored and saved data\helmet\images\train\000432.jpg
[34m[1mtrain: [39m[22mWARNING: corrupt JPEG restored and saved data\helmet\images\train\000485.jpg
[34m[1mtrain: [39m[22mWARNING: corrupt JPEG restored and saved data\helmet\images\train\000487.jpg
[34m[1mtrain: [39m[22mWARNING: corrupt JPEG restored and saved data\helmet\images\train\000499.jpg
[34m[1mtrain: [39m[22mWARNING: Cache directory data\helmet\labels is not writeable: [WinError 183] å½“æ–‡ä»¶å·²å­˜åœ¨æ—¶ï¼Œæ— æ³•åˆ›å»ºè¯¥æ–‡ä»¶ã€‚: 'data\\helmet\\labels\\train.cache.npy' -> 'data\\helmet\\labels\\train.cache'
[34m[1mval: [39m[22mScanning 'data\helmet\labels\val' images and labels...200 found, 0 missing, 0 empty, 0 corrupted: 100%|â–ˆ| 200/200
[34m[1mval: [39m[22mWARNING: Cache directory data\helmet\labels is not writeable: [WinError 183] å½“æ–‡ä»¶å·²å­˜åœ¨æ—¶ï¼Œæ— æ³•åˆ›å»ºè¯¥æ–‡ä»¶ã€‚: 'data\\helmet\\labels\\val.cache.npy' -> 'data\\helmet\\labels\\val.cache'
Image sizes 640 train, 640 val
Using 4 dataloader workers
Logging results to [1mruns\train\exp2
Starting training for 50 epochs...
     Epoch   gpu_mem       box       obj       cls    labels  img_size
  0%|                                                                                           | 0/38 [00:10<?, ?it/s]
Traceback (most recent call last):
  File "train.py", line 616, in <module>
    main(opt)
  File "train.py", line 513, in main
    train(opt.hyp, opt, device, callbacks)
  File "train.py", line 315, in train
    pred = model(imgs)  # forward
  File "C:\Users\chenxindaaa\anaconda3\envs\course_yolov5\lib\site-packages\torch\nn\modules\module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "D:\Study\PyCharm20\PycharmProjects\course_yolov5\yolov5-master\yolov5-master\models\yolo.py", line 124, in forward
    return self._forward_once(x, profile, visualize)  # single-scale inference, train
  File "D:\Study\PyCharm20\PycharmProjects\course_yolov5\yolov5-master\yolov5-master\models\yolo.py", line 146, in _forward_once
    x = m(x)  # run
  File "C:\Users\chenxindaaa\anaconda3\envs\course_yolov5\lib\site-packages\torch\nn\modules\module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "D:\Study\PyCharm20\PycharmProjects\course_yolov5\yolov5-master\yolov5-master\models\common.py", line 206, in forward
    return self.conv(torch.cat([x[..., ::2, ::2], x[..., 1::2, ::2], x[..., ::2, 1::2], x[..., 1::2, 1::2]], 1))
  File "C:\Users\chenxindaaa\anaconda3\envs\course_yolov5\lib\site-packages\torch\nn\modules\module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "D:\Study\PyCharm20\PycharmProjects\course_yolov5\yolov5-master\yolov5-master\models\common.py", line 45, in forward
    return self.act(self.bn(self.conv(x)))
  File "C:\Users\chenxindaaa\anaconda3\envs\course_yolov5\lib\site-packages\torch\nn\modules\module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "C:\Users\chenxindaaa\anaconda3\envs\course_yolov5\lib\site-packages\torch\nn\modules\activation.py", line 394, in forward
    return F.silu(input, inplace=self.inplace)
  File "C:\Users\chenxindaaa\anaconda3\envs\course_yolov5\lib\site-packages\torch\nn\functional.py", line 1796, in silu
    return torch._C._nn.silu(input)
KeyboardInterrupt